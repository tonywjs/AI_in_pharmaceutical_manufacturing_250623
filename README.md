# 페니실린 발효 데이터 기반 머신러닝 프로젝트 아이디어

이 데이터는 제약 공정 데이터를 다루는 머신러닝 프로젝트에 아주 좋은 예시입니다. 데이터의 특성을 활용하여 다음과 같은 흥미로운 머신러닝 모델을 만들어 볼 수 있습니다.

### 1. 페니실린 농도 단기 예측 모델 (회귀 문제)

*   **문제 정의**: 현재 공정 상태를 바탕으로 다음 시점(0.2시간 후)의 페니실린 농도(`Penicillin concentration`)를 실시간 예측합니다.
*   **머신러닝 유형**: 회귀 (Regression)
*   **주요 특성 (입력 변수)**:
    *   현재 시점의 공정 변수들: `Aeration rate`, `Agitator RPM`, `Sugar feed rate`, `Acid flow rate`, `Base flow rate`, `Dissolved oxygen concentration`, `pH`, `Temperature`, `Substrate concentration` (총 9개 변수)
*   **목표 변수 (예측 대상)**: 다음 시점(0.2시간 후)의 `Penicillin concentration(P:g/L)`.
*   **구현 방법**:
    *   **LightGBM 회귀 모델**을 사용하여 높은 성능 달성 (R² = 0.9710, MAE = 1.1080)
    *   전체 데이터의 20%를 샘플링하여 학습 속도 최적화
    *   특성 중요도 분석을 통해 `Time`이 가장 중요한 변수임을 확인
*   **데이터 특성**:
    *   100개 배치에서 총 22,687개의 데이터 포인트 생성
    *   각 배치는 고유한 발효 패턴을 보임
*   **기대 효과**: 실시간 공정 모니터링을 통해 단기적인 페니실린 농도 변화를 예측하여 즉각적인 공정 조정 및 최적화가 가능합니다.


---------------(예정)---------------------


### 2. 공정 이상 탐지 모델 (분류 또는 이상치 탐지 문제)

*   **문제 정의**: 실시간으로 공정 데이터를 모니터링하여, 공정이 정상 범주를 벗어나는 이상 징후(`Fault flag`)를 조기에 감지합니다.
*   **머신러닝 유형**: 이진 분류 (Binary Classification) 또는 이상치 탐지 (Anomaly Detection)
*   **주요 특성 (입력 변수)**: `Time`에 따른 모든 센서 데이터 (`Aeration rate`, `RPM`, `pH`, `Temperature`, `DO2` 등).
*   **목표 변수 (예측 대상)**: `Fault flag` (0: 정상, 1: 이상).
*   **구현 방법**:
    *   **지도학습**: `Fault flag`를 레이블로 사용하여 LSTM, Transformer 기반의 분류 모델을 학습시킵니다.
    *   **비지도학습**: 정상 데이터만으로 Autoencoder와 같은 딥러닝 모델을 학습시킨 후, 복원 오차(reconstruction error)가 큰 데이터를 이상치로 탐지할 수 있습니다. 이는 라벨링된 이상 데이터가 적을 때 유용합니다.
*   **기대 효과**: 설비 고장이나 오염 등으로 인한 배치 실패를 사전에 방지하여 손실을 최소화하고, 제품의 품질을 안정적으로 유지할 수 있습니다.

### 3. 최종 품질 예측 및 공정 최적화 (회귀 및 강화학습)

*   **문제 정의**: 공정 변수들을 어떻게 제어해야 페니실린 생산량을 극대화할 수 있는지 최적의 제어 정책을 찾습니다.
*   **머신러닝 유형**: 회귀 (Regression) + 강화학습 (Reinforcement Learning)
*   **접근 방식**:
    1.  **디지털 트윈 (Digital Twin) 구축**: 먼저, 현재 공정 상태와 제어 변수(`Aeration rate`, `Sugar feed rate` 등)를 입력받아 다음 상태(예: 1시간 뒤의 `Penicillin concentration`, `Biomass concentration`)를 예측하는 시뮬레이션 모델을 만듭니다. (LSTM, GRU 모델 활용)
    2.  **강화학습 에이전트 훈련**: 구축된 디지털 트윈 환경 내에서 강화학습 에이전트가 다양한 제어 정책을 시도하며 페니실린 생산량을 보상(reward)으로 받아 학습하게 합니다.
*   **기대 효과**: 사람의 경험에만 의존하는 것이 아닌, 데이터 기반의 최적의 공정 운영 방법을 도출하여 생산 효율을 극대화할 수 있습니다.
